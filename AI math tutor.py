# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bs4ffjwjeI3jmb-lfcDbd0TZnb32D81R
"""

!pip install streamlit openai langchain langchain_community faiss-cpu pypdf pyttsx3 speechrecognition

import os
os.environ["OPENAI_API_KEY"] = "your_api_key_here"

import os
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def call_llm(messages, temperature=0.4):
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=temperature
    )
    return response.choices[0].message.content

from langchain_community.document_loaders import PyPDFLoader

def load_pdf(path):
    loader = PyPDFLoader(path)
    return loader.load()

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings

def create_vectorstore(docs):
    embeddings = OpenAIEmbeddings()
    return FAISS.from_documents(docs, embeddings)

def voice_supported():
    try:
        import streamlit as st
        return False
    except:
        return True

def speak(text):
    try:
        import pyttsx3
        engine = pyttsx3.init()
        engine.say(text)
        engine.runAndWait()
    except:
        pass

import json
import os

PATH = "data/progress.json"

def load_progress():
    if not os.path.exists(PATH):
        return {}
    return json.load(open(PATH))

def update_progress(user, topic, correct):
    data = load_progress()
    data.setdefault(user, {})
    data[user].setdefault(topic, {"attempts": 0, "correct": 0})
    data[user][topic]["attempts"] += 1
    if correct:
        data[user][topic]["correct"] += 1
    json.dump(data, open(PATH, "w"), indent=2)

import streamlit as st
import os

# from utils.llm import call_llm
# from utils.progress import update_progress, load_progress
# from rag.loader import load_pdf
# from rag.vectorstore import create_vectorstore
# from utils.voice import speak

st.set_page_config("AI Math Tutor", layout="centered")
st.title("ðŸ“˜ AI Math Tutor (LLM-Powered)")

user = st.sidebar.text_input("User Name", "student")
level = st.sidebar.selectbox("Level", ["Beginner", "Intermediate", "Advanced"])
mode = st.sidebar.radio("Mode", ["Teach", "Quiz"])
topic = st.sidebar.text_input("Topic", "Matrices")

# Ensure the 'prompts' directory exists and create dummy prompt files if they don't
prompt_dir = "prompts"
if not os.path.exists(prompt_dir):
    os.makedirs(prompt_dir)

prompt_files = {
    "math_tutor_prompt.txt": "You are an AI Math tutor. Explain math concepts clearly and concisely. Always provide examples. Explain like you are talking to a {level} student.",
    "quiz_prompt.txt": "You are an AI Math Quiz generator. Create a {level} level quiz on {topic} with 3 multiple-choice questions and 1 free-response question. Provide the correct answers and explanations for each question at the end.",
    "evaluator_prompt.txt": "You are an AI Math Quiz Evaluator. Review the provided answer to a math quiz. If the answer is correct or mostly correct, respond with 'Correct'. If the answer is incorrect or significantly flawed, respond with 'Incorrect'. Provide constructive feedback regardless of correctness. Focus on mathematical accuracy and clarity of explanation. Do not reveal the correct answer if the user's answer is incorrect."
}

for filename, default_content in prompt_files.items():
    filepath = os.path.join(prompt_dir, filename)
    if not os.path.exists(filepath):
        with open(filepath, "w") as f:
            f.write(default_content)

# Load prompts
tutor_prompt = open("prompts/math_tutor_prompt.txt").read()
quiz_prompt = open("prompts/quiz_prompt.txt").read()
eval_prompt = open("prompts/evaluator_prompt.txt").read()

# PDF RAG
pdf = st.sidebar.file_uploader("Upload Math PDF", type="pdf")
context = ""

if pdf:
    with open("temp.pdf", "wb") as f:
        f.write(pdf.read())
    docs = load_pdf("temp.pdf")
    store = create_vectorstore(docs)
    context = "\n".join([d.page_content[:500] for d in docs[:2]])
    st.sidebar.success("PDF loaded")

# TEACH MODE
if mode == "Teach":
    question = st.text_input("Ask your math question")

    if st.button("Explain"):
        messages = [
            {"role": "system", "content": tutor_prompt},
            {"role": "user", "content": f"""
Level: {level}
Topic: {topic}
Context: {context}
Question: {question}
"""}
        ]
        response = call_llm(messages)
        st.write(response)
        speak(response)

# QUIZ MODE
if mode == "Quiz":
    if st.button("Generate Quiz"):
        quiz = call_llm([
            {"role": "system", "content": quiz_prompt.format(topic=topic, level=level)}
        ])
        st.session_state.quiz = quiz

    st.write(st.session_state.get("quiz", ""))

    ans = st.text_area("Your Answer")

    if st.button("Submit"):
        feedback = call_llm([
            {"role": "system", "content": eval_prompt},
            {"role": "user", "content": f"Quiz:\n{st.session_state.quiz}\nAnswer:\n{ans}"}
        ])
        st.write(feedback)

        correct = "correct" in feedback.lower()
        update_progress(user, topic, correct)

# DASHBOARD
st.markdown("---")
st.subheader("ðŸ“Š Progress")
st.json(load_progress().get(user, {}))